//There are two kinds of configurations "common" and then specific to main class.
//We should use com.zhimo.datahub.common.ConfigHelper class to access configurations.
//If configuration "kafka.topic_client_log" is selected, it is first searched if it is
//defined in specific main class configurations, if it's not found then it's returned from
//common configurations.

common{
  environment = "dev"
  localDev = true
  processFromStart = true
  verifySave = false
  showResults = true

  //LEGACY TO DELETE
  mysql {
    server_prod = "jdbc:mysql://mk.zhimo.co:53306/libra?useUnicode=true&characterEncoding=UTF-8"
    user_prod = "bigdata"
    pass_prod = "r08zBVAf6j70"

    server_dev = "jdbc:mysql://10.10.102.16:3306/libra?useUnicode=true&characterEncoding=UTF-8"
    user_dev = "zhimotest"
    pass_dev = "zhimotest#123"
  }

  kafka {
    server = "10.10.100.11:9092"
    server_localDev = "localhost:9092"
    interval = 3600
    topic {
      client = "useraction_%s"
      server = "MK-server-log_%s"
    }
    backupKafkaTopic = "mk_sparkanalysisbackup_%s" //LEGACY TO DELETE
  }

  storage{
    client = "clientlog_%s"
    server{
      payment = "payment_%s"
      refund = "refund_%s"
    }
    relations{
      class_relation = "class_relation_%s"
    }
  }

  result{
    client{
      basics = "basics_%s"
      retentions = "retention_%s"
      funnels = "funnels_%s"
    }
    server{
      revenue = "revenue_%s"
      refund = "refund_%s"
    }
  }


  location{
    overwrite = false
    ranges {
      source = "tmp/geolocation-ranges.csv"
      table = "geolocation_ranges"
    }
    ids{
      source = "tmp/geolocation-ids.csv"
      table = "geolocation_ids"
    }
  }

  permanentStorage = "tmp/default_%s.parquet"
  hiveStorage = "default_%s"
}

MKServerLog2Consumer{
  environment = "prod"
  kafka{
    topic = "MK-server-log_%s"
  }
  localDev = false
  processFromStart = true
  permanentStorage_payment = "tmp/payment_%s.parquet"
  permanentStorage_refund = "tmp/refund_%s.parquet"
  hiveStorage_payment = "payment_%s"
  hiveStorage_refund = "refund_%s"
}

MKBasicMetricsConsumer{
  kafka{
    topic = "useraction_%s"
  }
  permanentStorage = "tmp/sessions_%s.parquet"
  hiveStorage = "sessions_%s"
  backupKafkaTopic = "mk_sparkanalysisbackup_%s"
}

MKTemplateConsumer{

}