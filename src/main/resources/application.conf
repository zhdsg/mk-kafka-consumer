//There are two kinds of configurations "common" and then specific to main class.
//We should use ConfigHelper class to access configurations.
//If configuration "kafka.topic_client_log" is selected, it is first searched if it is
//defined in specific main class configurations, if it's not found then it's returned from
//common configurations.

common{
  environment = "dev"
  localDev = true
  processFromStart = true
  verifySave = false
  showResults = true

  //LEGACY TO DELETE
  mysql {
    server_prod = "jdbc:mysql://mk.zhimo.co:53306/libra?useUnicode=true&characterEncoding=UTF-8"
    user_prod = "bigdata"
    pass_prod = "r08zBVAf6j70"

    server_dev = "jdbc:mysql://10.10.102.16:3306/libra?useUnicode=true&characterEncoding=UTF-8"
    user_dev = "zhimotest"
    pass_dev = "zhimotest#123"
  }

  kafka {
    server = "10.10.100.11:9092"
    server_localDev = "localhost:9092"
    topic {
      client = "useraction_%s"
      server = "MK-server-log_%s"
    }
    backupKafkaTopic = "mk_sparkanalysisbackup_%s" //LEGACY TO DELETE
  }

  storage{
    client = "clientlog_%s"
    server{
      payment = "payment_%s"
      refund = "refund_%s"
    }
    relations{
      course = "course_%s"
      class = "class_%s"
      grade = "grade_%s"
      subject = "subject_%s"
      teacher = "teacher_%s"
    }
  }

  result{
    client{
      sessions = "sessions_%s"
      dau = "dau_%s"
      wau = "wau_%s"
      mau = "mau_%s"
      d1retention = "d1retention_%s"
      d7retention = "d7retention_%s"
      d30retention = "d30retention_%s"
    }
  }

  permanentStorage = "tmp/default_%s.parquet"
  hiveStorage = "default_%s"
}

MKServerLog2Consumer{
  environment = "prod"
  kafka{
    topic = "MK-server-log_%s"
  }
  localDev = false
  processFromStart = true
  permanentStorage_payment = "tmp/payment_%s.parquet"
  permanentStorage_refund = "tmp/refund_%s.parquet"
  hiveStorage_payment = "payment_%s"
  hiveStorage_refund = "refund_%s"
}

MKBasicMetricsConsumer{
  kafka{
    topic = "useraction_%s"
  }
  permanentStorage = "tmp/sessions_%s.parquet"
  hiveStorage = "sessions_%s"
  backupKafkaTopic = "mk_sparkanalysisbackup_%s"
}

MKTemplateConsumer{

}